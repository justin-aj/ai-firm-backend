# AI Firm Backend

An intelligent **Retrieval-Augmented Generation (RAG) system** that answers questions by searching the web, scraping relevant content, and using a local LLM (GPT-OSS-20B) to generate contextual answers. Features **smart topic-based caching** to avoid redundant scraping.

## ğŸ¯ Project Idea

**Problem**: LLMs have knowledge cutoffs and can't access real-time information.

**Solution**: Our system creates a **dynamic knowledge base** that:
1. ğŸ” **Analyzes** user questions to extract topics
2. ğŸ§  **Checks** if we already have content on similar topics (smart caching)
3. ğŸŒ **Searches** Google only when needed (saves API calls)
4. ğŸ“„ **Scrapes** web content and stores it with embeddings
5. ğŸ¯ **Retrieves** the most relevant context from our vector database
6. ğŸ’¬ **Generates** answers using GPT-OSS-20B with retrieved context

### Key Innovation: **Smart Topic Caching**
- Maintains a lightweight topics database
- Compares new questions against previously explored topics
- Skips scraping when we already have relevant content
- Dramatically reduces latency and API costs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Question                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Topic Analyzer â”‚ (LLM extracts topics)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Topics Cache   â”‚ (Milvus: ai_firm_topics)
                    â”‚ Check Similar? â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                 â”‚
    Similar?                          Not Similar?
        â”‚                                 â”‚
        â†“                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use Cached    â”‚              â”‚ Google Custom Searchâ”‚
â”‚ Content       â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â†“
        â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚ Crawl4AI Scraper    â”‚
        â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                  â†“
        â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚ BGE-M3 Embeddings   â”‚
        â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                  â†“
        â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚ Store in Milvus     â”‚
        â”‚                       â”‚ - Full Content      â”‚
        â”‚                       â”‚ - Topics Index      â”‚
        â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Retrieve Top 5 Docs â”‚ (Vector similarity search)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ GPT-OSS-20B         â”‚ (Generate answer with context)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Final Answer      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### Core RAG Pipeline
- **ğŸ¤– LLM-Based Topic Extraction** - GPT-OSS-20B analyzes questions intelligently
- **ğŸ“Š Dual Vector Storage** - Separate collections for topics (fast) and content (comprehensive)
- **ğŸ” Google Custom Search** - Real-time web search integration
- **ğŸ•·ï¸ Crawl4AI Scraping** - Extract markdown content from any URL
- **ğŸ§® BGE-M3 Embeddings** - 1024-dimensional multilingual embeddings
- **ğŸ’¾ Milvus Vector DB** - Efficient similarity search with L2 distance
- **âš¡ Smart Caching** - Topic-based deduplication (saves ~70% of scraping)

### Additional Features
- **FastAPI REST API** - Modern async endpoints
- **Model Context Protocol (MCP)** - Direct tool access for AI assistants
- **LM Studio Integration** - Local LLM support
- **Lazy Loading** - Heavy dependencies load only when needed
- **CORS Enabled** - Ready for frontend integration
- **Security Hardened** - Input validation, error handling, logging

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- LM Studio with GPT-OSS-20B model loaded
- Google Custom Search API credentials
- Milvus vector database (standalone or docker)

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
copy .env.example .env
```

Edit `.env` with your credentials:
```env
# Google Custom Search
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CX=your_custom_search_engine_id

# LM Studio (GPT-OSS-20B)
LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1

# Milvus Vector Database
MILVUS_HOST=localhost
MILVUS_PORT=19530

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true
```

### 3. Start Required Services

**Start Milvus:**
```bash
# Using Docker
docker run -d --name milvus-standalone \
  -p 19530:19530 \
  -p 9091:9091 \
  milvusdb/milvus:latest
```

**Start LM Studio:**
1. Open LM Studio
2. Load GPT-OSS-20B model (or any compatible model)
3. Start local server (port 1234)

### 4. Run the API Server

```bash
python main.py
```

Access at: **http://localhost:8000**

### 5. Test the RAG Pipeline

```bash
curl -X POST http://localhost:8000/intelligent-query/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is CUDA and how does it help with GPU programming?",
    "temperature": 0.7,
    "max_tokens": 2048
  }'
```

**First request:** Scrapes web, stores in Milvus (~15-20 seconds)  
**Subsequent similar requests:** Uses cached content (~2-3 seconds) âš¡

## ğŸ“¡ API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Main Endpoint: `/intelligent-query/ask`

**Request:**
```json
{
  "question": "Your question here",
  "temperature": 0.7,
  "max_tokens": 2048
}
```

**Response:**
```json
{
  "success": true,
  "topics": ["topic1", "topic2", "topic3"],
  "search_results": [...],
  "scraped_content": [...],
  "stored_in_milvus": true,
  "milvus_ids": [1, 2, 3, 4, 5],
  "retrieved_context": [
    {
      "id": 1,
      "score": 0.23,
      "text": "Relevant content...",
      "metadata": {"url": "...", "topics": [...]}
    }
  ],
  "llm_answer": "Based on the context, CUDA is..."
}
```

### Status Endpoint: `/intelligent-query/status`

Check if all services are operational:
```bash
curl http://localhost:8000/intelligent-query/status
```

## Project Structure

```
ai-firm-backend/
â”œâ”€â”€ main.py                    # FastAPI application entry point
â”œâ”€â”€ mcp_server.py             # MCP server with tools
â”œâ”€â”€ run_mcp_server.py         # MCP server runner
â”œâ”€â”€ config.py                 # Configuration management
â”œâ”€â”€ models.py                 # Pydantic models
â”œâ”€â”€ clients/                  # External service clients
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lm_studio_client.py   # LM Studio integration
â”‚   â”œâ”€â”€ google_search_client.py # Google Search integration
â”‚   â””â”€â”€ web_scraper_client.py # Crawl4AI web scraper
â”œâ”€â”€ routes/                   # API route handlers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py              # Core endpoints (health, root)
â”‚   â”œâ”€â”€ lm_studio.py         # LM Studio endpoints
â”‚   â”œâ”€â”€ search.py            # Google Search endpoints
â”‚   â”œâ”€â”€ scraper.py           # Web scraping endpoints
â”‚   â””â”€â”€ sequential_thinking.py # Sequential thinking endpoints
â”œâ”€â”€ tests/                    # Test files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_dask.py         # Dask integration tests
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ MCP_SETUP.md         # MCP configuration guide
â”‚   â”œâ”€â”€ SECURITY.md          # Security best practices
â”‚   â”œâ”€â”€ DEPLOYMENT_CHECKLIST.md # Deployment guide
â”‚   â”œâ”€â”€ DASK_GUIDE.md        # Dask distributed scraping guide
â”‚   â””â”€â”€ MODULARIZATION.md    # Code organization notes
â”œâ”€â”€ .env                      # Environment variables (local, gitignored)
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ requirements.txt          # Python dependencies
```
